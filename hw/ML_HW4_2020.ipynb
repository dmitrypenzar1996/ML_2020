{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы занятия взяты из курса Никиты Котлярова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обязательные баллы\n",
    "\n",
    "За это дз надо набрать 30 баллов. Все баллы выше этой планки - дополнительные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.datasets import make_classification, make_blobs, make_circles, make_moons, load_digits\n",
    "from sklearn.utils import shuffle as sklearn_shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "В этой работе вам необходимо будет обучать модели машинного обучения, подбирать гиперпараметры, сравнивать и смешивать модели. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
    " - age\n",
    " - workclass\n",
    " - fnlwgt\n",
    " - education\n",
    " - education-num\n",
    " - marital-status\n",
    " - occupation\n",
    " - relationship\n",
    " - race\n",
    " - sex\n",
    " - capital-gain\n",
    " - capital-loss\n",
    " - hours-per-week\n",
    " \n",
    "Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*.\n",
    "\n",
    "Датасет - https://drive.google.com/file/d/1EyhatnsqrOuPPcreH8Pbz-eDpSJDHkqz/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных *data.adult.csv* с помощью `pandas`. Чтобы посмотреть данные, можно вызвать для загруженного `DataFrame` метод `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла)** Для некоторых объектов могут быть пропущены значения некоторых признаков. Пропуски могут обозначаться либо значением `numpy.nan`, либо каким-то определенным значением, которое указывается в описании к набору данных. В данном датасете пропущенные значения обозначены как \"?\". \n",
    "\n",
    "Некоторые алгоритмы могут работать некорректно с пропущенными значениями. Примените к выборке один из методов обработки пропущенных значений. Обоснуйте свой выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее проделайте следующее:\n",
    " - Перемешайте объекты, чтобы исключить возможные последствия изначальной сортировки данных.\n",
    " - Выделите метки классов в отдельный вектор, удалите их из матрицы \"объект-признак\" и преобразуйте метки классов к бинарному формату (+1, -1).\n",
    " - Оставьте в датасете только вещественные признаки; сначала мы будем работать только с ними.\n",
    " \n",
    "Более подробно о работе с пропусками в Pandas можно прочитать, например, [здесь](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение классификаторов на вещественных признаках\n",
    "\n",
    "**Важно!** Для оценки качества используйте метрику ROC-AUC.\n",
    "\n",
    "В начале посмотрим, как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 2\n",
    "алгоритма:\n",
    " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала оптимизируем один гиперпараметр у DecisonTree — глубина дерева (*max_depth*)\n",
    " \n",
    "Остальные параметры пусть принимают значения по умолчанию. Для подбора гиперпараметров воспользуйтесь перебором по сетке, который реализован в классе [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). В качестве схемы кросс-валидации используйте 5-Fold CV: [KFoldCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6 баллов)** Для каждого алгоритма подберите оптимальные значения указанных гиперпараметров. Постройте график среднего значения качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразите доверительный интервал (значение качества на каждом фолде, среднее значение качества и много другой полезной информации можно получить из поля [*cv results_*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)). Построение графика стоит выделить в отдельную функцию - это избавит вас от дублирования кода при выполнении дальнейшего задания.\n",
    "\n",
    "Что вы можете сказать о получившихся графиках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла)** Также подберём число деревьев (*n_estimators*) в алгоритме RandomForest. В общем случае Random Forest не переобучается с увеличением количества деревьев. Подберите значение гиперпараметра, на которой ощутимый прирост качества перестает наблюдаться. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев. Обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества деревьев разных размеров, состоящих из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте подобранное количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла)** Качество алгоритмов может зависеть не только от значений гиперпараметров, но и от предобратки исходных признаков. Некоторые из рассматриваемых нами алгоритмов чувствительны к масштабу признаков. Посмотрим, насколько различны распределения признаков. Постройте гистограммы для признаков *age*, *fnlwgt*, *capital-gain*.\n",
    "\n",
    "Глядя на получившиеся графики, скажите в чем заключается особенность данных? На какие алгоритмы это может повлиять? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака\n",
    "\n",
    "Похожие схемы масштабирования приведены в классах [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) и [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
    " \n",
    "**(2 балла)** Масштабируйте все вещественные признаки одним из указанных способов и подберите оптимальные значения гиперпараметров аналогично пункту выше.\n",
    "\n",
    "Изменилось ли качество у алгоритмов и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4 балла)** Теперь сделайте перебор гиперпараметров по сетке и найдите оптимальные комбинации для следующих моделей и гиперпараметров: \n",
    " - DecisonTree — глубина дерева (*max_depth*) и критерий разбиения (*criterion*)\n",
    " - RandomForest — критерий разбиения в деревьях (*criterion*) и *max_features* (при фиксированном количестве деревьев, найденном ранее), в качестве глубины деревьев возьмите ту, что подобрана для одиночного решающего дерева (или чуть большую)\n",
    "\n",
    "Нарисуйте соответствующие графики.\n",
    "Обратите внимание, что эта операция может быть ресурсо- и трудоемкой.\n",
    "\n",
    "Какой из алгоритмов имеет наилучшее качество?\n",
    "\n",
    "(для оптимизации кода и вычислений перед выполнением прочитайте следующее задание)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла)** Сравните алгоритмы с точки зрения времени обучения и предсказания. Какой из алгоритмов работает дольше всего и почему?\n",
    "\n",
    "(hint: [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) подсчитывает не только качество на кросс-валидации, но и время работы алгоритмов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление категориальных признаков в модели\n",
    "\n",
    "Вспомним, что у нас еще есть категориальные признаки. Давайте посмотрим, как изменится качество модели после добавления этих признаков. \n",
    "\n",
    "**(1 балл)** Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) из sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как после кодирования признаков получилось достаточно много, в этой работе мы не будем добавлять их и подбирать заново оптимальные гиперпараметры (хотя правильнее было бы это сделать). \n",
    "\n",
    "**(3 балла)** Добавьте к масштабированным вещественным признакам закодированные категориальные и обучите алгоритмы с наилучшими гиперпараметрами из предыдущего пункта. Дало ли добавление новых признаков прирост качества? Измеряйте качество как и раньше используя 5-Fold CV. Для этого удобно воспользоваться функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score).\n",
    "\n",
    "Отличается ли теперь наилучший классификатор от наилучшего в предыдущем пункте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация \n",
    "В следующем блоке мы рассмотрим задачу кластеризации.\n",
    "\n",
    "Для начала предлагается проанализировать поведение различных метрик. Сложно дать четкое определение, что такое хорошая кластеризация, однако можно сформулировать некоторые ее признаки:\n",
    "\n",
    "объекты внутри кластера должны быть похожи друг на друга,\n",
    "похожие объекты должны попадать в один кластер (этот пункт не следует из предыдущего!),\n",
    "в случае, когда нам известны истинные метки классов, метрика не должна учитывать абсолютные значения меток объектов, полученных из кластеризации.\n",
    "Вам предлагается сравнить 4 различных метрики:\n",
    "\n",
    "Homogeneity, Completeness и V-measure\n",
    "Adjusted Rand index\n",
    "Для выполнения задания используйте датасет, составленный из рукописных \"картинок\" цифр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits, labels = sklearn_shuffle(*load_digits(return_X_y=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "digits, labels = sklearn_shuffle(*load_digits(return_X_y=True))\n",
    "# В labels собраны названия цифр, в digits - их векторное представление:\n",
    "\n",
    "f, axarr = plt.subplots(3, 4, figsize=(12, 12))\n",
    "plt.gray()\n",
    "for ax, digit, label in zip(axarr.flatten(), digits, labels):\n",
    "    ax.matshow(digit.reshape(8, 8))\n",
    "    ax.tick_params(top='off', labeltop='off', left='off', labelleft='off', bottom='off')\n",
    "    ax.set_title(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1 балл**) Кластеризуйте изображения при помощи алгоритма KMeans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 балла**. Поcтройте графики зависимости значений метрик от числа кластеров (рекомендуется рассмотреть от 2 до 20 кластеров). Если графики получаются зашумленным, запустите алгоритм несколько раз из разных случайных положений центроидов и усредните результат.\n",
    "Визуализируйте изображения, соответствующие центроидам лучшей кластеризации. Что представляют собой эти изображения?\n",
    "Визуализируйте несколько изображений, которые были отнесены к неправильному кластеру в случае лучшей кластеризации. Как вы думаете, почему они были неправильно кластеризованы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши данные имеют относительно высокую размерность - 64. Попробуем уменьшить размерность и попробовать другие алгоритмы кластеризации.\n",
    "\n",
    "(**2 балла**) Для наглядности попробуем уложить наши данные в двухмерное пространство. Примените PCA, tSNE и UMAP к имеющися данным и визуалируйте полученный результат. Чем отличаются результаты этих двух подходов?\n",
    "\n",
    "\n",
    "\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**до 7 баллов**) К данным уменьшенной размерности примените алгоритмы кластеризации KMeans, DBSCAN, и AffinityPropagation. Подбор параметров - на ваше усмотрение. Для каких-то методов можно даже не делать перебор или ограничиться небольшой сеткой, главное - аргументировать, почему в этом случае это уместно. Метрику выберите на свою усмотрение, пояснив свой выбор.\n",
    "\n",
    "Визуалируйте результат кластеризации (с лучшими параметрами) на каждом из способов уменьшения размерности.\n",
    "\n",
    "Как вы считаете, помогло ли уменьшение размерности в данном датасете? Улучшено ли качество в сравнении с KMeans на полных данных? Сравните алгоритмы кластеризации: в чем преимущества и недостатки каждого из них?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost и все-все-все"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работать вам предстоит с датасетом, составленным из рукописных \"картинок\" цифр. \n",
    "Он вам знаком по предыдущему заданию (можете брать код для работы с ним оттуда). Только в этот раз мы возьмем его полную версию - картинки будут размером 28х28 вместо 8х8, а общее число картинок - 42000 вместо 1797.\n",
    "\n",
    "https://www.tensorflow.org/datasets/catalog/mnist\n",
    "\n",
    "Загрузите датасет и разбейте его на выборки для обучения и контроля. Можете использовать приведенную выше ссылку, можете найти другие \n",
    "\n",
    "\n",
    "Для ускорения работы возьмите небольшую часть датасета, например, 3%. Отладьте на ней код, а потом запустите расчеты на больших данных.\n",
    "\n",
    "Скорее всего, вычисления будут трудоемкими, если брать весь датасет, поэтому для итоговых вычислений можете взять только его часть \n",
    "(но не меньше 30%).\n",
    "\n",
    "Обратите внимание, что наблюдаемые результаты могут сильно зависеть от того, делаете ли вы эксперимент на маленьких или больших данных.\n",
    "Так, на выборке размера 100 ваш классификатор может легко переобучиться,\n",
    "в то время как на выборке размера 10000 этот эффект может не наблюдаться. Поэтому делайте выводы после запуска расчетов на больших данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv('train.csv')\n",
    "    data = data.sample(frac=SAMPLE_FRACTION)\n",
    "    labels = data['label'].values\n",
    "    digits = data.drop('label', 1).values\n",
    "    return digits, labels\n",
    "\n",
    "digits, labels = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**3 балла**)\n",
    "Давайте в качестве базового решения посмотрим на известные нам алгоритмы. Возьмите kNN и Random Forest. Обучите их (гиперпараметры оставьте по умолчанию), подсчитайте точность и logloss на тестовой выборке. Какой алгоритм дал лучший результат? Как различаются алгоритмы по качеству и времени обучения и предсказания?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее целевой метрикой для нас будет logloss. Точность также будем вычислять, как более интерпретируемую метрику.\n",
    "\n",
    "## XGBoost\n",
    "\n",
    "\n",
    "Установите библиотеку xgboost. Реализация бустинга есть и в sklearn, но в ней уделено сильно меньше внимания регуляризации\n",
    "и скорости, поэтому мы будем использовать xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1 балл**) Возьмите классификатор с настройками по умолчанию (рекомендуется установить n_jobs на -1 для ускорения расчета). \n",
    "Оцените его качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем потюнить XGBoost.\n",
    "\n",
    "(**1 балл**) Выберите относительно большую learning_rate (𝜂∈[0.05,0.3]), подберите оптимальное число деревьев для выбранного 𝜂. В методе fit задайте eval_metric, равное mlogloss, в eval_set передайте [(X_test, y_test)]; таким образом, вы сможете получать качество вашей классификации после каждого обученного базового классификатора. Вы можете регулировать \"болтливость\" метода обучения с помощью параметры verbose (например, задать его равным 10).\n",
    "\n",
    "(**2 балла**)\n",
    "Постройте график зависимости качества классификации от числа базовых классификаторов (для этого можете воспользоваться методом evals_result). Для большей наглядности можете отдельно отобразить график по последним 60 точкам. Как вам кажется, какое количество базовых классификаторов будет оптимальным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**3 балла**) Зафиксируйте выбранное количество деревьев. Настройте параметры деревьев, начиная с самых значимых (max_depth, min_child_weight, gamma, colsample_bytree). Более подробно подробно про эти параметры вы можете почитать в документации, указанной выше. Не забывайте, что бустинг, как правило, хорошо работает на деревьях небольшой глубины.\n",
    "\n",
    "Правильно подбирать эти параметры по сетке, но данный перебор был бы чересчур трудоемким. Поэтому подбирайте их последовательно.\n",
    "\n",
    "Считать score на каждом шаге не нужно, сравнивайте только обученные классификаторы. Сохраняйте качество (accuracy и logloss) вашего классификатора после каждого настроенного параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1 балл**) Далее таким же образом настройте регуляризацию (𝜆,𝛼)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1 балл**) После того, как все параметры настроены, уменьшите learning_rate, пропорционально увеличив число деревьев. Обучите итоговый классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**3 балла**)\n",
    "Постройте 2 графика:\n",
    "\n",
    "по оси X отложены этапы настройки классификатора: по умолчанию, после выбора числа деревьев, после настройки каждого гиперпараметра, итоговый классификатор;\n",
    "по оси Y на первом графике - roc-auc на каждом этапе, на втором - pr-auc.\n",
    "Какой этап дал наиболее существенный прирост качества? Получилось ли у вас поднять качество выше, чем у базовых решений: kNN и Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
